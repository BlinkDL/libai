dataloader:
  test:
  - _target_: libai.data.build_image_test_loader
    dataset:
      _target_: libai.data.datasets.CIFAR100Dataset
      dataset_name: cifar100 test set
      download: true
      root: ./
      train: false
      transform:
        _target_: flowvision.transforms.Compose
        transforms:
        - _target_: flowvision.transforms.Resize
          interpolation: !!python/object/apply:flowvision.transforms.functional.InterpolationMode [bicubic]
          size: 256
        - {_target_: flowvision.transforms.CenterCrop, size: 224}
        - {_target_: flowvision.transforms.ToTensor}
        - _target_: flowvision.transforms.Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    num_workers: 4
  train:
    _target_: libai.data.build_image_train_loader
    dataset:
    - _target_: libai.data.datasets.CIFAR100Dataset
      dataset_name: cifar100 train set
      download: true
      root: ./
      train: true
      transform:
        _target_: flowvision.transforms.Compose
        transforms:
        - _target_: flowvision.transforms.RandomResizedCrop
          interpolation: 3
          ratio: [0.75, 1.3333333333333333]
          scale: [0.08, 1.0]
          size: 224
        - {_target_: flowvision.transforms.RandomHorizontalFlip, p: 0.5}
        - _target_: flowvision.data.rand_augment_transform
          config_str: rand-m9-mstd0.5-inc1
          hparams:
            img_mean: [124, 116, 104]
            interpolation: 3
            translate_const: 100
        - _target_: flowvision.transforms.Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
        - {_target_: flowvision.transforms.ToTensor}
        - {_target_: flowvision.data.RandomErasing, device: cpu, max_count: 1, mode: pixel, num_splits: 0, probability: 0.25}
    mixup_func: {_target_: flowvision.data.Mixup, cutmix_alpha: 1.0, mixup_alpha: 0.8, mode: batch, num_classes: 1000, prob: 1.0, switch_prob: 0.5}
    num_workers: 4
graph:
  debug: -1
  enabled: true
  eval_graph: {_target_: libai.models.utils.GraphBase, is_train: false}
  train_graph: {_target_: libai.models.utils.GraphBase, is_train: true}
model:
  _target_: libai.models.VisionTransformer
  attn_drop_rate: 0.0
  depth: 12
  drop_path_rate: 0.1
  drop_rate: 0.0
  embed_dim: 192
  img_size: 224
  in_chans: 3
  loss_func: {_target_: flowvision.loss.cross_entropy.SoftTargetCrossEntropy}
  mlp_ratio: 4.0
  num_classes: 1000
  num_heads: 3
  patch_size: 16
optim:
  _target_: oneflow.nn.optimizer.adamw.AdamW
  betas: [0.9, 0.999]
  do_bias_correction: true
  eps: 1.0e-08
  lr: 0.0005
  parameters: {_target_: libai.optim.get_default_optimizer_params, clip_grad_max_norm: 1.0, clip_grad_norm_type: 2.0, weight_decay_bias: 0.0, weight_decay_norm: 0.0}
  weight_decay: 0.05
train:
  amp: {enabled: true}
  checkpointer: {max_to_keep: 100, period: 5000}
  consumed_train_samples: 0
  consumed_valid_samples: 0
  dist: {data_parallel_size: 8, num_gpus_per_node: 8, num_nodes: 1, pipeline_num_layers: 10000, pipeline_parallel_size: 1, tensor_parallel_size: 1}
  eval_metric: Acc@1
  eval_mode: max
  eval_period: 1000
  global_batch_size: 128
  load_weight: ''
  log_period: 1
  nccl_fusion_max_ops: 24
  nccl_fusion_threshold_mb: 16
  num_accumulation_steps: 1
  output_dir: ./output
  recompute_grad: {enabled: false}
  resume: false
  scheduler: {_target_: libai.scheduler.WarmupCosineLR, alpha: 0.01, warmup_factor: 0.001, warmup_method: linear}
  seed: 1234
  start_iter: 0
  test_micro_batch_size: 128
  topk: [1, 5]
  train_epoch: 300
  train_iter: 10000
  train_micro_batch_size: 16
  train_samples: null
  warmup_ratio: 0.06666666666666667
  zero_optimization: {enabled: false, stage: 1}
